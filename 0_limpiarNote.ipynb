{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "\n",
    "\n",
    "df = pd.read_csv(path + '/airline_passenger_satisfaction.csv')\n",
    "\n",
    "#Se elimina la primera columna que era el subíndice del csv\n",
    "df = df.iloc[:, 1:] \n",
    "df=df.drop(columns='id') #no sé si al final quito el id porque me estorba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay que crear una parte que sea 'test'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=22 )\n",
    "\n",
    "# test_size=0.2, este parámetro indica que deseas que el 20% de los datos se utilicen como conjunto de prueba y el 80% como conjunto de entrenamiento. \n",
    "# random_state=22 Este parámetro establece una semilla para el generador de números aleatorios que se usa para realizar la división. Esto asegura que cada vez que ejecutes el código, obtendrás la misma división de los datos en conjuntos de entrenamiento y prueba. Usar un valor de random_state fijo es una buena práctica cuando quieres que tus resultados sean reproducibles.\n",
    "\n",
    "train.to_csv(path+'df_train.csv', index=False)\n",
    "test.to_csv(path+'df_test.csv', index=False)\n",
    "#Este test no lo tocamos hasta el final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Exploración y visualización de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103904 entries, 0 to 103903\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   Gender                             103904 non-null  object \n",
      " 1   Customer Type                      103904 non-null  object \n",
      " 2   Age                                103904 non-null  int64  \n",
      " 3   Type of Travel                     103904 non-null  object \n",
      " 4   Class                              103904 non-null  object \n",
      " 5   Flight Distance                    103904 non-null  int64  \n",
      " 6   Inflight wifi service              103904 non-null  int64  \n",
      " 7   Departure/Arrival time convenient  103904 non-null  int64  \n",
      " 8   Ease of Online booking             103904 non-null  int64  \n",
      " 9   Gate location                      103904 non-null  int64  \n",
      " 10  Food and drink                     103904 non-null  int64  \n",
      " 11  Online boarding                    103904 non-null  int64  \n",
      " 12  Seat comfort                       103904 non-null  int64  \n",
      " 13  Inflight entertainment             103904 non-null  int64  \n",
      " 14  On-board service                   103904 non-null  int64  \n",
      " 15  Leg room service                   103904 non-null  int64  \n",
      " 16  Baggage handling                   103904 non-null  int64  \n",
      " 17  Checkin service                    103904 non-null  int64  \n",
      " 18  Inflight service                   103904 non-null  int64  \n",
      " 19  Cleanliness                        103904 non-null  int64  \n",
      " 20  Departure Delay in Minutes         103904 non-null  int64  \n",
      " 21  Arrival Delay in Minutes           103594 non-null  float64\n",
      " 22  satisfaction                       103904 non-null  object \n",
      "dtypes: float64(1), int64(17), object(5)\n",
      "memory usage: 18.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "El DF tiene 103,904 filas\n",
      "El DF tiene 23 columnas\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\nEl DF tiene {df.shape[0]:,} filas')\n",
    "print(f'El DF tiene {df.shape[1]} columnas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   conteo_nulos  proporcion%\n",
      "Gender                                        0        0.000\n",
      "Customer Type                                 0        0.000\n",
      "Age                                           0        0.000\n",
      "Type of Travel                                0        0.000\n",
      "Class                                         0        0.000\n",
      "Flight Distance                               0        0.000\n",
      "Inflight wifi service                         0        0.000\n",
      "Departure/Arrival time convenient             0        0.000\n",
      "Ease of Online booking                        0        0.000\n",
      "Gate location                                 0        0.000\n",
      "Food and drink                                0        0.000\n",
      "Online boarding                               0        0.000\n",
      "Seat comfort                                  0        0.000\n",
      "Inflight entertainment                        0        0.000\n",
      "On-board service                              0        0.000\n",
      "Leg room service                              0        0.000\n",
      "Baggage handling                              0        0.000\n",
      "Checkin service                               0        0.000\n",
      "Inflight service                              0        0.000\n",
      "Cleanliness                                   0        0.000\n",
      "Departure Delay in Minutes                    0        0.000\n",
      "Arrival Delay in Minutes                    310        0.298\n",
      "satisfaction                                  0        0.000\n"
     ]
    }
   ],
   "source": [
    "# Comprobar cuántos valores missing existen en el DataFrame por variable\n",
    "\n",
    "nulos={'conteo_nulos':df.isnull().sum(),'proporcion%':round(df.isnull().sum()/df.shape[0]*100, 3)}\n",
    "\n",
    "df_nulos=pd.DataFrame(data=nulos)\n",
    "print(df_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Type\n",
       "Loyal Customer       84923\n",
       "disloyal Customer    18981\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conteo de los valores por cada columna ----> Hacer bucle para ver si hay columnas que estén desbalanceadas.\n",
    "# Para ver qué variables hay que escalar\n",
    "\n",
    "df['Customer Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de convertir las variables categóricas, hay que tratar los 'missings'.\n",
    "\n",
    "Que según hemos concluido, tantos los valores '0' como los 'espacios en blanco' son 'missing' y los vamos a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "El DF tiene 103,594 filas\n",
      "                                   conteo_nulos  proporcion%\n",
      "Gender                                        0          0.0\n",
      "Customer Type                                 0          0.0\n",
      "Age                                           0          0.0\n",
      "Type of Travel                                0          0.0\n",
      "Class                                         0          0.0\n",
      "Flight Distance                               0          0.0\n",
      "Inflight wifi service                         0          0.0\n",
      "Departure/Arrival time convenient             0          0.0\n",
      "Ease of Online booking                        0          0.0\n",
      "Gate location                                 0          0.0\n",
      "Food and drink                                0          0.0\n",
      "Online boarding                               0          0.0\n",
      "Seat comfort                                  0          0.0\n",
      "Inflight entertainment                        0          0.0\n",
      "On-board service                              0          0.0\n",
      "Leg room service                              0          0.0\n",
      "Baggage handling                              0          0.0\n",
      "Checkin service                               0          0.0\n",
      "Inflight service                              0          0.0\n",
      "Cleanliness                                   0          0.0\n",
      "Departure Delay in Minutes                    0          0.0\n",
      "Arrival Delay in Minutes                      0          0.0\n",
      "satisfaction                                  0          0.0\n"
     ]
    }
   ],
   "source": [
    "# Primero elimino los 'missings'\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "print(f'\\n\\nEl DF tiene {df.shape[0]:,} filas')\n",
    "\n",
    "\n",
    "# Compruebo que se ha eliminado\n",
    "nulos={'conteo_nulos':df.isnull().sum(),'proporcion%':round(df.isnull().sum()/df.shape[0]*100, 3)}\n",
    "df_nulos=pd.DataFrame(data=nulos)\n",
    "print(df_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora elimino los '0' pero de las columnas categóricas ordinales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables categóricas ordinales: ['Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
      "8179\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "# Función para detectar variables categóricas ordinales\n",
    "def detectar_variables_ordinales(df):\n",
    "    ordinal_columns = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        # verificar si la columna es numérica\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # obtener valores únicos\n",
    "            unique_values = df[column].unique()\n",
    "            # verificar si todos los valores están en el rango [1,5]\n",
    "            if set(unique_values).issubset({0, 1, 2, 3, 4, 5}):\n",
    "                ordinal_columns.append(column)\n",
    "\n",
    "    \n",
    "    return ordinal_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "variables_ordinales = detectar_variables_ordinales(df)\n",
    "print(\"Variables categóricas ordinales:\", variables_ordinales)\n",
    "rows_with_zero = (df[variables_ordinales] == 0).any(axis=1).sum()\n",
    "print(rows_with_zero)\n",
    "\n",
    "print(len(variables_ordinales))\n",
    "# Resultado:\n",
    "# Variables categóricas ordinales: ['Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
    "# De esas variables hay que quitar los '0' porque hemos decidido que son missing. Antes de hacer el one-hot-encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']\n"
     ]
    }
   ],
   "source": [
    "# Variables que son categóricas binarias y categóricas no ordinales\n",
    "import pandas as pd\n",
    "\n",
    "def detectar_variables_categoricas(df):\n",
    "    categorias_columns = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        # Verificar si la columna no es numérica\n",
    "        if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Obtener el número de categorías únicas\n",
    "            unique_values = df[column].nunique()\n",
    "            # Se puede agregar un límite arbitrario si se desea,\n",
    "            # por ejemplo, menos de 10 categorías únicas\n",
    "            if unique_values < 10:\n",
    "                categorias_columns.append(column)\n",
    "\n",
    "    return categorias_columns\n",
    "\n",
    "# Supongamos que tienes un DataFrame df\n",
    "variables_categoricas = detectar_variables_categoricas(df)\n",
    "print(variables_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro para quedarme con las numéricas, las que voy a escalar\n",
    "\n",
    "# Primero detecto las columnas que tienen solo valores de 0 y 1\n",
    "\"\"\" binary_cols = x_encoded.columns[x_encoded.nunique() == 2]\n",
    "\n",
    "# Luego detecto las columnas ordinales (2 a 5)\n",
    "ordinal_cols = x_encoded.columns[(x_encoded.nunique() > 1) & (x_encoded.nunique() <= 5)] \"\"\"\n",
    "\n",
    "# Ambas categóricas las junto \n",
    "categorical_cols = list(variables_categoricas) + list(variables_ordinales)\n",
    "\n",
    "print(categorical_cols)\n",
    "print(len(categorical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo las variables categóricas de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Gender      Customer Type   Type of Travel     Class  \\\n",
      "0         Male     Loyal Customer  Personal Travel  Eco Plus   \n",
      "1         Male  disloyal Customer  Business travel  Business   \n",
      "2       Female     Loyal Customer  Business travel  Business   \n",
      "3       Female     Loyal Customer  Business travel  Business   \n",
      "4         Male     Loyal Customer  Business travel  Business   \n",
      "...        ...                ...              ...       ...   \n",
      "103899  Female  disloyal Customer  Business travel       Eco   \n",
      "103900    Male     Loyal Customer  Business travel  Business   \n",
      "103901    Male  disloyal Customer  Business travel  Business   \n",
      "103902  Female  disloyal Customer  Business travel       Eco   \n",
      "103903    Male     Loyal Customer  Business travel  Business   \n",
      "\n",
      "                   satisfaction  Inflight wifi service  \\\n",
      "0       neutral or dissatisfied                      3   \n",
      "1       neutral or dissatisfied                      3   \n",
      "2                     satisfied                      2   \n",
      "3       neutral or dissatisfied                      2   \n",
      "4                     satisfied                      3   \n",
      "...                         ...                    ...   \n",
      "103899  neutral or dissatisfied                      2   \n",
      "103900                satisfied                      4   \n",
      "103901  neutral or dissatisfied                      1   \n",
      "103902  neutral or dissatisfied                      1   \n",
      "103903  neutral or dissatisfied                      1   \n",
      "\n",
      "        Departure/Arrival time convenient  Ease of Online booking  \\\n",
      "0                                       4                       3   \n",
      "1                                       2                       3   \n",
      "2                                       2                       2   \n",
      "3                                       5                       5   \n",
      "4                                       3                       3   \n",
      "...                                   ...                     ...   \n",
      "103899                                  1                       2   \n",
      "103900                                  4                       4   \n",
      "103901                                  1                       1   \n",
      "103902                                  1                       1   \n",
      "103903                                  3                       3   \n",
      "\n",
      "        Gate location  Food and drink  Online boarding  Seat comfort  \\\n",
      "0                   1               5                3             5   \n",
      "1                   3               1                3             1   \n",
      "2                   2               5                5             5   \n",
      "3                   5               2                2             2   \n",
      "4                   3               4                5             5   \n",
      "...               ...             ...              ...           ...   \n",
      "103899              3               2                2             2   \n",
      "103900              4               2                4             5   \n",
      "103901              3               4                1             5   \n",
      "103902              5               1                1             1   \n",
      "103903              3               1                1             1   \n",
      "\n",
      "        Inflight entertainment  On-board service  Leg room service  \\\n",
      "0                            5                 4                 3   \n",
      "1                            1                 1                 5   \n",
      "2                            5                 4                 3   \n",
      "3                            2                 2                 5   \n",
      "4                            3                 3                 4   \n",
      "...                        ...               ...               ...   \n",
      "103899                       2                 3                 1   \n",
      "103900                       5                 5                 5   \n",
      "103901                       4                 3                 2   \n",
      "103902                       1                 4                 5   \n",
      "103903                       1                 1                 1   \n",
      "\n",
      "        Baggage handling  Checkin service  Inflight service  Cleanliness  \n",
      "0                      4                4                 5            5  \n",
      "1                      3                1                 4            1  \n",
      "2                      4                4                 4            5  \n",
      "3                      3                1                 4            2  \n",
      "4                      4                3                 3            3  \n",
      "...                  ...              ...               ...          ...  \n",
      "103899                 4                2                 3            2  \n",
      "103900                 5                5                 5            4  \n",
      "103901                 4                5                 5            4  \n",
      "103902                 1                5                 4            1  \n",
      "103903                 4                4                 3            1  \n",
      "\n",
      "[103594 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "data_cat=df[categorical_cols]\n",
    "data_num=df.drop(columns=categorical_cols)\n",
    "\n",
    "print(data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conteo de '0's por columna:\n",
      "\n",
      " Inflight wifi service                3096\n",
      "Departure/Arrival time convenient    5290\n",
      "Ease of Online booking               4473\n",
      "Gate location                           1\n",
      "Food and drink                        105\n",
      "Online boarding                      2420\n",
      "Seat comfort                            1\n",
      "Inflight entertainment                 14\n",
      "On-board service                        3\n",
      "Leg room service                      470\n",
      "Baggage handling                        0\n",
      "Checkin service                         1\n",
      "Inflight service                        3\n",
      "Cleanliness                            12\n",
      "dtype: int64\n",
      "\n",
      "Total de '0's en todas las columnas: 15,889\n"
     ]
    }
   ],
   "source": [
    "\"\"\" count_zeros = (df == 0).sum().sum()\n",
    "print(count_zeros) \"\"\"\n",
    "\n",
    "# Contar los valores iguales a 0 en las columnas ordinales\n",
    "conteo_ceros = (df[variables_ordinales] == 0).sum()   ## conteo_ceros = df[variables_ordinales].apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Sumar el conteo para obtener el total de ceros en todas las columnas\n",
    "total_ceros = conteo_ceros.sum()\n",
    "\n",
    "# Mostrar\n",
    "print(\"\\nConteo de '0's por columna:\\n\\n\", conteo_ceros)\n",
    "print(f\"\\nTotal de '0's en todas las columnas: {total_ceros:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sin_ceros = df[(df[variables_ordinales] != 0).all(axis=1)]#.reset_index()\n",
    "\n",
    "df_sin_ceros = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conteo de ceros por columna:\n",
      "\n",
      " Inflight wifi service                3096\n",
      "Departure/Arrival time convenient    5290\n",
      "Ease of Online booking               4473\n",
      "Gate location                           1\n",
      "Food and drink                        105\n",
      "Online boarding                      2420\n",
      "Seat comfort                            1\n",
      "Inflight entertainment                 14\n",
      "On-board service                        3\n",
      "Leg room service                      470\n",
      "Baggage handling                        0\n",
      "Checkin service                         1\n",
      "Inflight service                        3\n",
      "Cleanliness                            12\n",
      "dtype: int64\n",
      "\n",
      "Total de ceros en todas las columnas: 15889\n",
      "Quedan 103,594 filas\n",
      "Número de filas que tenían algún '0' en las columnas ordinales: 8179\n"
     ]
    }
   ],
   "source": [
    "\"\"\" for col in variables_ordinales:\n",
    "    df_sin_ceros = df[df[col] != 0] #df_sin_ceros = df[(df != 0).all(axis=1)]\n",
    "    \n",
    "     \"\"\"\n",
    "    \n",
    "    \n",
    "#Vuelto a contar los '0's en el dataframe de las variables ordinales para comprobar que se han eliminado\n",
    "conteo_ceros = (df_sin_ceros[variables_ordinales] == 0).sum()   ## conteo_ceros = df[variables_ordinales].apply(lambda x: (x == 0).sum())\n",
    "\n",
    "#¿Porque predice mal? o porque está sesgado (es inherente a la muestra tomada)\n",
    "# Aleatorio no es lo mismo que representativa\n",
    "\n",
    "# Sumar el conteo para obtener el total de ceros en todas las columnas\n",
    "total_ceros = conteo_ceros.sum()\n",
    "\n",
    "# Mostrar\n",
    "print(\"\\nConteo de ceros por columna:\\n\\n\", conteo_ceros)\n",
    "print(\"\\nTotal de ceros en todas las columnas:\", total_ceros)\n",
    "\n",
    "print(f'Quedan {df_sin_ceros.shape[0]:,} filas')\n",
    "# Contar las filas que contienen algún 0 en las columnas especificadas\n",
    "rows_with_zero = (df[variables_ordinales] == 0).any(axis=1).sum()\n",
    "\n",
    "print(f\"Número de filas que tenían algún '0' en las columnas ordinales: {rows_with_zero}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de hacer la matriz de correlación, hay que convertir las columnas que son 'object' a binarias.\n",
    "\n",
    "(pero cuidado, PRIMERO hay que separar la variable objetivo, que es una columna del dataframe)\n",
    "\n",
    "**One-Hot Encoding es generalmente preferido cuando no hay un orden inherente en las categorías. De esta manera, me aseguro de que el modelo no asuma relaciones incorrectas entre las categorías.\n",
    "\n",
    "**Label Encoding podría usarse si hay un orden claro entre las categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Gender_Male  Gender_Female  Customer Type_Loyal Customer  \\\n",
      "0                 1              0                             1   \n",
      "1                 1              0                             0   \n",
      "2                 0              1                             1   \n",
      "3                 0              1                             1   \n",
      "4                 1              0                             1   \n",
      "...             ...            ...                           ...   \n",
      "103899            0              1                             0   \n",
      "103900            1              0                             1   \n",
      "103901            1              0                             0   \n",
      "103902            0              1                             0   \n",
      "103903            1              0                             1   \n",
      "\n",
      "        Customer Type_disloyal Customer  Age  Type of Travel_Personal Travel  \\\n",
      "0                                     0   13                               1   \n",
      "1                                     1   25                               0   \n",
      "2                                     0   26                               0   \n",
      "3                                     0   25                               0   \n",
      "4                                     0   61                               0   \n",
      "...                                 ...  ...                             ...   \n",
      "103899                                1   23                               0   \n",
      "103900                                0   49                               0   \n",
      "103901                                1   30                               0   \n",
      "103902                                1   22                               0   \n",
      "103903                                0   27                               0   \n",
      "\n",
      "        Type of Travel_Business travel  Class_Eco Plus  Class_Business  \\\n",
      "0                                    0               1               0   \n",
      "1                                    1               0               1   \n",
      "2                                    1               0               1   \n",
      "3                                    1               0               1   \n",
      "4                                    1               0               1   \n",
      "...                                ...             ...             ...   \n",
      "103899                               1               0               0   \n",
      "103900                               1               0               1   \n",
      "103901                               1               0               1   \n",
      "103902                               1               0               0   \n",
      "103903                               1               0               1   \n",
      "\n",
      "        Class_Eco  ...  Seat comfort  Inflight entertainment  \\\n",
      "0               0  ...             5                       5   \n",
      "1               0  ...             1                       1   \n",
      "2               0  ...             5                       5   \n",
      "3               0  ...             2                       2   \n",
      "4               0  ...             5                       3   \n",
      "...           ...  ...           ...                     ...   \n",
      "103899          1  ...             2                       2   \n",
      "103900          0  ...             5                       5   \n",
      "103901          0  ...             5                       4   \n",
      "103902          1  ...             1                       1   \n",
      "103903          0  ...             1                       1   \n",
      "\n",
      "        On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
      "0                      4                 3                 4                4   \n",
      "1                      1                 5                 3                1   \n",
      "2                      4                 3                 4                4   \n",
      "3                      2                 5                 3                1   \n",
      "4                      3                 4                 4                3   \n",
      "...                  ...               ...               ...              ...   \n",
      "103899                 3                 1                 4                2   \n",
      "103900                 5                 5                 5                5   \n",
      "103901                 3                 2                 4                5   \n",
      "103902                 4                 5                 1                5   \n",
      "103903                 1                 1                 4                4   \n",
      "\n",
      "        Inflight service  Cleanliness  Departure Delay in Minutes  \\\n",
      "0                      5            5                          25   \n",
      "1                      4            1                           1   \n",
      "2                      4            5                           0   \n",
      "3                      4            2                          11   \n",
      "4                      3            3                           0   \n",
      "...                  ...          ...                         ...   \n",
      "103899                 3            2                           3   \n",
      "103900                 5            4                           0   \n",
      "103901                 5            4                           7   \n",
      "103902                 4            1                           0   \n",
      "103903                 3            1                           0   \n",
      "\n",
      "        Arrival Delay in Minutes  \n",
      "0                           18.0  \n",
      "1                            6.0  \n",
      "2                            0.0  \n",
      "3                            9.0  \n",
      "4                            0.0  \n",
      "...                          ...  \n",
      "103899                       0.0  \n",
      "103900                       0.0  \n",
      "103901                      14.0  \n",
      "103902                       0.0  \n",
      "103903                       0.0  \n",
      "\n",
      "[103594 rows x 27 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" # Dividir los datos en conjuntos de entrenamiento y prueba\\nx_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.2, random_state=42)\\n\\n# Guardar datos en ficheros\\npath='C:/4_F5/011_proyecto_ml/'\\nx_train.to_csv(path + '/x_train.csv')\\nx_test.to_csv(path + '/x_test.csv')\\ny_train.to_csv(path + '/y_train.csv')\\ny_test.to_csv(path + '/y_test.csv')\\n \""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Separar la variable objetivo antes de la codificación, la llamo 'y'.\n",
    "# Si no la separo todavía, la va a codificar, lo cual no sé si conviene por el momento.\n",
    "#y = df_sin_ceros['satisfaction']\n",
    "\n",
    "#-- Codificar solo las variables categóricas--\n",
    "\n",
    "# Variables categóricas\n",
    "encoder_cat = ce.OneHotEncoder(use_cat_names=True)\n",
    "x_encoded = encoder_cat.fit_transform(df_sin_ceros.drop(columns=['satisfaction']))\n",
    "print(x_encoded)\n",
    "\n",
    "\n",
    "# Variables categóricas ordinales\n",
    "# Crear OrdinalEncoder\n",
    "encoder_ord = OrdinalEncoder()\n",
    "# Aplicar OrdinalEncoder a múltiples variables categóricas ordinales.\n",
    "# Machaco la variable x_encoded que la recojo de la codificación anterior.\n",
    "x_encoded  = pd.DataFrame(encoder_ord.fit_transform(x_encoded), columns=x_encoded.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Concatenar la columna 'satisfaccion' de nuevo al DataFrame codificado\n",
    "df_encoded = pd.concat([x_encoded, y], axis=1)\n",
    "\n",
    "\"\"\" # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Guardar datos en ficheros\n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "x_train.to_csv(path + '/x_train.csv')\n",
    "x_test.to_csv(path + '/x_test.csv')\n",
    "y_train.to_csv(path + '/y_train.csv')\n",
    "y_test.to_csv(path + '/y_test.csv')\n",
    " \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cuando tienes un DataFrame con columnas categóricas y categóricas ordinales, es importante elegir el método de codificación adecuado que preserve la naturaleza ordinal de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor  # Esto importa pyjanitor y extiende pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a separar las variables, por un lado según sean categóricas(binarias, ordinales..) y por otro las numéricas\n",
    "\n",
    "· Categóricas\n",
    "\n",
    "· Numéricas\n",
    "\n",
    "Porque a veces un modelo va a trabajar mejor sólo con las categóricas o sólo con las numéricas.\n",
    "Además, es conveniente escalar las variables munéricas (ya sean por cambios de escala o por magnitud, o incluso 'normalizarlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction', 'Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "\"\"\" #Filtro para quedarme con las numéricas, las que voy a escalar\n",
    "\n",
    "# Primero detecto las columnas que tienen solo valores de 0 y 1\n",
    "binary_cols = x_encoded.columns[x_encoded.nunique() == 2]\n",
    "\n",
    "# Luego detecto las columnas ordinales (2 a 5)\n",
    "ordinal_cols = x_encoded.columns[(x_encoded.nunique() > 1) & (x_encoded.nunique() <= 5)]\n",
    "\n",
    "# Ambas categóricas las junto \n",
    "categorical_cols = list(variables_categoricas) + list(variables_ordinales)\n",
    "\n",
    "print(categorical_cols)\n",
    "print(len(categorical_cols)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué este orden es importante?\n",
    "\n",
    "Consistencia: Al separar primero X e y y luego hacer el split, garantizas que las filas correspondientes de X e y coincidan exactamente en los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Evitar filtraciones de datos: Si haces el split antes de separar X e y, podrías accidentalmente introducir fugas de datos o inconsistencias, lo que podría afectar la capacidad del modelo para generalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primero separas la 'y' de las variables predictoras 'x'.\n",
    "* Luego El split de tanto 'y' como 'x' con su correspondiente 'train' y 'test'\n",
    "* Finalmente voy a escalar las numéricas: Después de realizar el split, ajustas el escalador (Scaler) solo con el conjunto de entrenamiento (X_train). Esto asegura que las estadísticas de escalado (media, desviación estándar, etc.) no estén influenciadas por los datos de prueba.\n",
    "* Aplicar la transformación de escalado al conjunto de prueba:Una vez que el escalador se ha ajustado al conjunto de entrenamiento, usas ese mismo escalador para transformar el conjunto de prueba (X_test). Esto asegura que ambos conjuntos sean escalados de manera consistente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las variables categóricas son 19:\n",
      "\n",
      "Gender\n",
      "Customer Type\n",
      "Type of Travel\n",
      "Class\n",
      "satisfaction\n",
      "Inflight wifi service\n",
      "Departure/Arrival time convenient\n",
      "Ease of Online booking\n",
      "Gate location\n",
      "Food and drink\n",
      "Online boarding\n",
      "Seat comfort\n",
      "Inflight entertainment\n",
      "On-board service\n",
      "Leg room service\n",
      "Baggage handling\n",
      "Checkin service\n",
      "Inflight service\n",
      "Cleanliness\n",
      "\n",
      "Index(['Gender_Male', 'Gender_Female', 'Customer Type_Loyal Customer',\n",
      "       'Customer Type_disloyal Customer', 'Age',\n",
      "       'Type of Travel_Personal Travel', 'Type of Travel_Business travel',\n",
      "       'Class_Eco Plus', 'Class_Business', 'Class_Eco', 'Flight Distance',\n",
      "       'Inflight wifi service', 'Departure/Arrival time convenient',\n",
      "       'Ease of Online booking', 'Gate location', 'Food and drink',\n",
      "       'Online boarding', 'Seat comfort', 'Inflight entertainment',\n",
      "       'On-board service', 'Leg room service', 'Baggage handling',\n",
      "       'Checkin service', 'Inflight service', 'Cleanliness',\n",
      "       'Departure Delay in Minutes', 'Arrival Delay in Minutes'],\n",
      "      dtype='object')\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#Primero separas la 'y' de las variables predictoras 'x'\n",
    "#Luego El split de tanto 'y' como 'x' con su correspondiente 'train' y 'test'\n",
    "#Finalmente voy a escalar las numéricas: Después de realizar el split, ajustas el escalador (Scaler) solo con el conjunto de entrenamiento (X_train). Esto asegura que las estadísticas de escalado (media, desviación estándar, etc.) no estén influenciadas por los datos de prueba.\n",
    "#Aplicar la transformación de escalado al conjunto de prueba:Una vez que el escalador se ha ajustado al conjunto de entrenamiento, usas ese mismo escalador para transformar el conjunto de prueba (X_test). Esto asegura que ambos conjuntos sean escalados de manera consistente\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "print(f'Las variables categóricas son {len(categorical_cols)}:\\n\\n' + '\\n'.join(categorical_cols) + '\\n')\n",
    "\n",
    "\n",
    "# Separa el dataframe en partes de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\"\"\" categorical_cols.remove('satisfaction')\n",
    "print(categorical_cols) \"\"\"\n",
    "\n",
    "print(x_train.columns)\n",
    "print(len(x_train.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Filtro o identifico cuáles son las columnas categóricas de 'x' y quedarme con las numéricas, porque son esas las que voy a escalar\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_num_train \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;66;03m#Aquí Sólo se están guardando el nombre de las columnas para rastrearlas\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(x_train[x_num_train])\u001b[38;5;241m.\u001b[39mto_csv(path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/x_num_train_no_scaled.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m x_num_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcategorical_cols)\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;66;03m#Sólo cojo el nombre de las columnas para rastrearlas\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nel_n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5570\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5574\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5575\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nel_n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4782\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4782\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\nel_n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4824\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4822\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4823\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4824\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4825\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4827\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4828\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nel_n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7069\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7069\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7070\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7071\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Filtro o identifico cuáles son las columnas categóricas de 'x' y quedarme con las numéricas, porque son esas las que voy a escalar\n",
    "x_num_train = x_train.drop(columns=categorical_cols).columns #Aquí Sólo se están guardando el nombre de las columnas para rastrearlas\n",
    "pd.DataFrame(x_train[x_num_train]).to_csv(path+'/x_num_train_no_scaled.csv', index=False)\n",
    "\n",
    "x_num_test = x_test.drop(columns=categorical_cols).columns #Sólo cojo el nombre de las columnas para rastrearlas\n",
    "pd.DataFrame(x_test[x_num_test]).to_csv(path+'/x_num_test_no_scaled.csv', index=False)\n",
    "\n",
    "\n",
    "print(f'Las variables numéricas son {x_num_train.shape[0]}:\\n\\n' + '\\n'.join(x_num_train) + '\\n')\n",
    "\n",
    "# Crea un objeto StandardScaler y ajusta los parámetros de escalado con la parte de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "x_train_num_scaled = scaler.fit_transform(x_train[x_num_train])\n",
    "\n",
    "# Aplica los parámetros de escalado aprendidos a la parte de prueba\n",
    "x_test_num_scaled = scaler.transform(x_test[x_num_test]) #devuelve un array de arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón es que, en general, deseas mantener la separación entre los datos de entrenamiento y los datos de prueba, incluso después de la escalado. De esta manera, puedes asegurarte de que el modelo de machine learning se entrena y se evalúa correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# En 'train' cojo las columnas numéricas sin escalar y las reemplazo con las columnas numéricas escaladas. \n",
    "# Por lo que ya me queda todo 'x_train' junto y escalado\n",
    "x_train[x_num_train] = x_train_num_scaled \n",
    "print(x_train)\n",
    "\n",
    "x_train.to_csv(path +   '/x_train_scaled.csv')\n",
    "\n",
    "# En 'test' cojo las columnas numéricas sin escalar y las reemplazo con las columnas numéricas escaladas.\n",
    "# Por lo que ya me queda todo 'x_test' junto y escalado\n",
    "x_test[x_num_test] = x_test_num_scaled\n",
    "x_test.to_csv(path + '/x_test_scaled.csv')\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos en ficheros\n",
    "\"\"\" \n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "pd.DataFrame(x_train_scaled).to_csv('x_train_scaled.csv', index=False)\n",
    "pd.DataFrame(x_test_scaled).to_csv('x_test_scaled.csv', index=False)\n",
    "y_train.to_csv(path + '/y_train.csv')\n",
    "y_test.to_csv(path + '/y_test.csv')\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histograma de la variable escalada\n",
    "plt.hist(x_test['Age'], bins=50)\n",
    "plt.title('Distribución de la variable escalada')\n",
    "plt.show()\n",
    "\n",
    "# Histograma de la variable no escalada ---> usar de A´ngel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estadísticas descriptivas de la variable escalada:')\n",
    "print(x_test['Age'].describe())\n",
    "\n",
    "print('Estadísticas descriptivas de la variable escalada:')\n",
    "#print(x_test_scaled[:, 0]).describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crea un objeto RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrena el modelo con el conjunto de entrenamiento\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evalúa el modelo con el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# ...\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calcula la accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calcula la precisión (average='weighted' for multi-class problems)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calcula el recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted',labels=['neutral or dissatisfied', 'satisfied'])\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "\"\"\" # Calcula el F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Calcula el ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "# Calcula la matriz de confusión\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicolinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train,y_train_le)\n",
    "\n",
    "\n",
    "#print(x_train.head())\n",
    "print(y_train.head())\n",
    "print(lin_reg.predict(x_train.head()))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "El problema es que el modelo de regresión lineal (LinearRegression) no entiende que tu variable objetivo es binaria.\n",
    "\n",
    "La regresión lineal es un algoritmo de aprendizaje automático que se utiliza para predecir valores continuos, no binarios. \n",
    "Cuando entrenas el modelo con tus datos, el algoritmo intenta encontrar la mejor línea que se ajuste a tus datos, pero no \n",
    "tiene en cuenta que la variable objetivo es binaria.\n",
    "\n",
    "Por lo tanto, cuando haces print(lin_reg.predict(x_train.head())), el modelo devuelve valores decimales porque está tratando de predecir un valor continuo, no un valor binario.\n",
    "\n",
    "Para solucionar este problema, debes utilizar un algoritmo de aprendizaje automático que sea adecuado para problemas de clasificación binaria, como LogisticRegression de scikit-learn. Este algoritmo entiende que la variable objetivo es binaria y devuelve probabilidades de pertenencia a cada clase, que puedes convertir en valores binarios (0 o 1) utilizando una función de umbral (threshold).\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Codificaicón de la variable objetivo\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train_le)\n",
    "\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_test_le = le.transform(y_test)  # Codifica y_test para compararlo correctamente\n",
    "y_pred = log_reg.predict(x_test)  # Predicción sobre el conjunto de prueba\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test_le, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Ejemplo de predicciones sobre nuevas muestras (primeras 5 filas del conjunto de prueba)\n",
    "print(x_test.head())\n",
    "y_pred_example = log_reg.predict(x_test.head())\n",
    "print(y_pred_example)\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': y_test_le[:5],  # Primeras 5 filas reales\n",
    "    'Predicción': y_pred_example # Primeras 5 predicciones\n",
    "})\n",
    "\n",
    "# Imprimir la tabla de resultados\n",
    "print(\"\\nValores reales vs. Predicciones:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de calcular la correlación entre las variables dummy, es más útil utilizar otras técnicas para seleccionar las variables más relevantes para el modelo. Algunas opciones son:\n",
    "\n",
    "Análisis de la importancia de las características: utiliza algoritmos como Random Forest o Gradient Boosting para evaluar la importancia de cada variable en la predicción de Y.\n",
    "Selección de características: utiliza técnicas como la selección recursiva de características (RFE) o la selección de características mediante la matriz de correlación de mutual information.\n",
    "Análisis de la varianza: utiliza técnicas como la descomposición de la varianza para evaluar la contribución de cada variable a la varianza de Y.\n",
    "Recuerda que la selección de variables es un paso importante en el proceso de modelado, y es importante utilizar técnicas adecuadas para identificar las variables más relevantes para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Codificación de la variable objetivo\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)  # Codifica y_test para compararlo correctamente\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train_le)\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred = log_reg.predict(x_test)  # Predicción sobre el conjunto de prueba\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test_le, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convertir las predicciones numéricas a etiquetas originales es por pura estética del 'satiesfied'\n",
    "y_pred_example_labels = le.inverse_transform(y_pred_example)\n",
    "print(\"\\nPredicciones con etiquetas originales:\")\n",
    "\n",
    "\n",
    "y_test_example_labels = le.inverse_transform(y_test_le)\n",
    "\n",
    "\n",
    "# Verificar si las predicciones son 'satisfied'\n",
    "print(\"\\n¿Las predicciones son 'satisfied'?\")\n",
    "\n",
    "# Mostrar los primeros 5 valores reales y predichos    \n",
    "# Crear un DataFrame para mostrar los resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': y_test_example_labels[:5],  # Primeras 5 filas reales\n",
    "    'Predicción': y_pred_example_labels[:5]  # Primeras 5 predicciones\n",
    "})\n",
    "\n",
    "# Imprimir la tabla de resultados\n",
    "print(\"\\nValores reales vs. Predicciones:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a usar más métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#\n",
    "# Generar la matriz de confusión\n",
    "cm = confusion_matrix(y_test_le, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión saca sus resultados a partir de lo parte de 'test', en general (pero se puede hacer una matriz de confusión de la parte de 'train' para comparar con la matriz de 'test' y así encontrar señales de 'overfitting'. Esto lo haré luego)\n",
    "\n",
    "Para interpretar esta matriz, debemos entender qué representan cada una de las celdas:\n",
    "\n",
    "La diagonal principal (de arriba a la izquierda a abajo a la derecha) representa las observaciones que el modelo clasificó correctamente. En este caso, hay 15005 observaciones que el modelo clasificó como negativas (0) y realmente eran negativas, y 10665 observaciones que el modelo clasificó como positivas (1) y realmente eran positivas.\n",
    "La celda superior derecha (1455) representa las observaciones que el modelo clasificó como positivas (1) pero realmente eran negativas (0). Estas son llamadas \"falsos positivos\" (FP).\n",
    "La celda inferior izquierda (1500) representa las observaciones que el modelo clasificó como negativas (0) pero realmente eran positivas (1). Estas son llamadas \"falsos negativos\" (FN).\n",
    "A partir de esta matriz de confusión, podemos sacar varias conclusiones:\n",
    "\n",
    "Precisión: La precisión del modelo se puede calcular como la suma de las observaciones clasificadas correctamente (diagonal principal) dividida entre el total de observaciones. En este caso, la precisión es (15005 + 10665) / (15005 + 1455 + 1500 + 10665) ≈ 0.92. Esto significa que el modelo es capaz de clasificar correctamente alrededor del 92% de las observaciones.\n",
    "\n",
    "Sensibilidad: La sensibilidad se refiere a la capacidad del modelo para detectar observaciones positivas (1). Se puede calcular como la cantidad de verdaderos positivos (TP) dividida entre la suma de verdaderos positivos y falsos negativos (FN). En este caso, la sensibilidad es 10665 / (10665 + 1500) ≈ 0.877. Esto significa que el modelo es capaz de detectar alrededor del 87.7% de las observaciones positivas.\n",
    "\n",
    "Especificidad: La especificidad se refiere a la capacidad del modelo para detectar observaciones negativas (0). Se puede calcular como la cantidad de verdaderos negativos (TN) dividida entre la suma de verdaderos negativos y falsos positivos (FP). En este caso, la especificidad es 15005 / (15005 + 1455) ≈ 0.912. Esto significa que el modelo es capaz de detectar alrededor del 91.2% de las observaciones negativas.\n",
    "En resumen, la matriz de confusión indica que el modelo de regresión logística tiene una buena precisión y especificidad, pero una sensibilidad moderada. Esto sugiere que el modelo es capaz de clasificar correctamente la mayoría de las observaciones, pero puede tener dificultades para detectar algunas observaciones positivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirar qué es sobreajuste y cómo medirlo\n",
    "\n",
    "El 'overfitting' es un problema que ocurre cuando un modelo de machine learning se ajusta demasiado bien a los datos de entrenamiento, capturando tanto las relaciones como el ruido o patrones irrelevantes en los datos.\n",
    "Como resultado, aunque el modelo tenga un alto rendimiento en los datos de entrenamiento, su capacidad de generalización a nuevos datos o datos de prueba deficiente, lo que conduce a un bajo rendimiento de estos últimos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del Modelo de Regresión Logística, algunas señales para evaluar Overfitting podría ser:\n",
    "* Alta precisión en el conjunto de entrenamiento y baja precisión en el conjunto de prueba.\n",
    "* Matriz de confusión desequilibrada, donde el modelo clasifica correctamente en el conjunto de entrenamiento, pero falla significativamente en el conjunto de prueba.\n",
    "* Curva ROC/AUC, donde el AUC en los datos de prueba es significativamente más bajo que en los datos de entrenamiento.\n",
    "\n",
    "\n",
    "Por tanto, se pueden realizar las siguientes comprobaciones para evaluarlo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":\n",
    "\n",
    "* 1. Compara el rendimiento entre los datos de entrenamiento y prueba: Revisa las métricas de precisión (accuracy), precisión (precision), sensibilidad (recall), y el AUC en ambos conjuntos de datos. Si el rendimiento es mucho mejor en el conjunto de entrenamiento que en el conjunto de prueba, es una señal clara de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción en el conjunto de entrenamiento\n",
    "y_train_pred = log_reg.predict(x_train)\n",
    "train_accuracy = accuracy_score(y_train_le, y_train_pred)\n",
    "\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", train_accuracy)\n",
    "print(\"Precisión en el conjunto de prueba:\", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2. Curva de aprendizaje: \n",
    "Podemos graficar el rendimiento del modelo en el conjunto de entrenamiento y prueba en función del número de muestras. Si la precisión en el conjunto de prueba se estabiliza a un nivel bajo y en el conjunto de entrenamiento es muy alta, esto es una indicación de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Parámetros para la función learning_curve\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)  # Fracciones del conjunto de datos de entrenamiento que se usarán\n",
    "\n",
    "# Generar curva de aprendizaje\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    LogisticRegression(), \n",
    "    x_train, y_train_le, \n",
    "    train_sizes=train_sizes, \n",
    "    cv=5,  # Validación cruzada de 5 folds\n",
    "    scoring='accuracy',  # Medimos la precisión del modelo\n",
    "    n_jobs=-1  # Usar todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Cálculo de la media y desviación estándar para la precisión de entrenamiento y validación\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "# Graficar la curva de aprendizaje\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Precisión en entrenamiento', color='blue')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color='blue', alpha=0.2)\n",
    "plt.plot(train_sizes, validation_scores_mean, label='Precisión en validación', color='green')\n",
    "plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std, validation_scores_mean + validation_scores_std, color='green', alpha=0.2)\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.title('Curva de aprendizaje para Regresión Logística')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo otro Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Preparación de los Algoritmos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Seleccionar un modelo y entrénalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Ajustar el modelo (optimización con hypermaprámetros, ensamblado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Presentar la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Desplegar y monitorizar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
