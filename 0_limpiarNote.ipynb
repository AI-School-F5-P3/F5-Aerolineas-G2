{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "\n",
    "\n",
    "df = pd.read_csv(path + '/airline_passenger_satisfaction.csv')\n",
    "\n",
    "#Se elimina la primera columna que era el subíndice del csv\n",
    "df = df.iloc[:, 1:] \n",
    "df=df.drop(columns='id') #no sé si al final quito el id porque me estorba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay que crear una parte que sea 'test'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=22 )\n",
    "\n",
    "# test_size=0.2, este parámetro indica que deseas que el 20% de los datos se utilicen como conjunto de prueba y el 80% como conjunto de entrenamiento. \n",
    "# random_state=22 Este parámetro establece una semilla para el generador de números aleatorios que se usa para realizar la división. Esto asegura que cada vez que ejecutes el código, obtendrás la misma división de los datos en conjuntos de entrenamiento y prueba. Usar un valor de random_state fijo es una buena práctica cuando quieres que tus resultados sean reproducibles.\n",
    "\n",
    "train.to_csv(path+'df_train.csv', index=False)\n",
    "test.to_csv(path+'df_test.csv', index=False)\n",
    "#Este test no lo tocamos hasta el final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Exploración y visualización de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n\\nEl DF tiene {df.shape[0]:,} filas')\n",
    "print(f'El DF tiene {df.shape[1]} columnas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar cuántos valores missing existen en el DataFrame por variable\n",
    "\n",
    "nulos={'conteo_nulos':df.isnull().sum(),'proporcion%':round(df.isnull().sum()/df.shape[0]*100, 3)}\n",
    "\n",
    "df_nulos=pd.DataFrame(data=nulos)\n",
    "print(df_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de los valores por cada columna ----> Hacer bucle para ver si hay columnas que estén desbalanceadas.\n",
    "# Para ver qué variables hay que escalar\n",
    "\n",
    "df['Customer Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de convertir las variables categóricas, hay que tratar los 'missings'.\n",
    "\n",
    "Que según hemos concluido, tantos los valores '0' como los 'espacios en blanco' son 'missing' y los vamos a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero elimino los 'missings'\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "print(f'\\n\\nEl DF tiene {df.shape[0]:,} filas')\n",
    "\n",
    "\n",
    "# Compruebo que se ha eliminado\n",
    "nulos={'conteo_nulos':df.isnull().sum(),'proporcion%':round(df.isnull().sum()/df.shape[0]*100, 3)}\n",
    "df_nulos=pd.DataFrame(data=nulos)\n",
    "print(df_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora elimino los '0' pero de las columnas categóricas ordinales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "# Función para detectar variables categóricas ordinales\n",
    "def detectar_variables_ordinales(df):\n",
    "    ordinal_columns = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        # verificar si la columna es numérica\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # obtener valores únicos\n",
    "            unique_values = df[column].unique()\n",
    "            # verificar si todos los valores están en el rango [1,5]\n",
    "            if set(unique_values).issubset({0, 1, 2, 3, 4, 5}):\n",
    "                ordinal_columns.append(column)\n",
    "\n",
    "    \n",
    "    return ordinal_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "variables_ordinales = detectar_variables_ordinales(df)\n",
    "print(\"Variables categóricas ordinales:\", variables_ordinales)\n",
    "rows_with_zero = (df[variables_ordinales] == 0).any(axis=1).sum()\n",
    "print(rows_with_zero)\n",
    "# Resultado:\n",
    "# Variables categóricas ordinales: ['Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
    "# De esas variables hay que quitar los '0' porque hemos decidido que son missing. Antes de hacer el one-hot-encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" count_zeros = (df == 0).sum().sum()\n",
    "print(count_zeros) \"\"\"\n",
    "\n",
    "# Contar los valores iguales a 0 en las columnas ordinales\n",
    "conteo_ceros = (df[variables_ordinales] == 0).sum()   ## conteo_ceros = df[variables_ordinales].apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Sumar el conteo para obtener el total de ceros en todas las columnas\n",
    "total_ceros = conteo_ceros.sum()\n",
    "\n",
    "# Mostrar\n",
    "print(\"\\nConteo de '0's por columna:\\n\\n\", conteo_ceros)\n",
    "print(f\"\\nTotal de '0's en todas las columnas: {total_ceros:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ceros = df[(df[variables_ordinales] != 0).all(axis=1)]#.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" for col in variables_ordinales:\n",
    "    df_sin_ceros = df[df[col] != 0] #df_sin_ceros = df[(df != 0).all(axis=1)]\n",
    "    \n",
    "     \"\"\"\n",
    "    \n",
    "    \n",
    "#Vuelto a contar los '0's en el dataframe de las variables ordinales para comprobar que se han eliminado\n",
    "conteo_ceros = (df_sin_ceros[variables_ordinales] == 0).sum()   ## conteo_ceros = df[variables_ordinales].apply(lambda x: (x == 0).sum())\n",
    "\n",
    "#¿Porque predice mal? o porque está sesgado (es inherente a la muestra tomada)\n",
    "# Aleatorio no es lo mismo que representativa\n",
    "\n",
    "# Sumar el conteo para obtener el total de ceros en todas las columnas\n",
    "total_ceros = conteo_ceros.sum()\n",
    "\n",
    "# Mostrar\n",
    "print(\"\\nConteo de ceros por columna:\\n\\n\", conteo_ceros)\n",
    "print(\"\\nTotal de ceros en todas las columnas:\", total_ceros)\n",
    "\n",
    "print(f'Quedan {df_sin_ceros.shape[0]:,} filas')\n",
    "# Contar las filas que contienen algún 0 en las columnas especificadas\n",
    "rows_with_zero = (df[variables_ordinales] == 0).any(axis=1).sum()\n",
    "\n",
    "print(f\"Número de filas que tenían algún '0' en las columnas ordinales: {rows_with_zero}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de hacer la matriz de correlación, hay que convertir las columnas que son 'object' a binarias.\n",
    "\n",
    "(pero cuidado, PRIMERO hay que separar la variable objetivo, que es una columna del dataframe)\n",
    "\n",
    "**One-Hot Encoding es generalmente preferido cuando no hay un orden inherente en las categorías. De esta manera, me aseguro de que el modelo no asuma relaciones incorrectas entre las categorías.\n",
    "\n",
    "**Label Encoding podría usarse si hay un orden claro entre las categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Separar la variable objetivo antes de la codificación, la llamo 'y'.\n",
    "# Si no la separo todavía, la va a codificar, lo cual no sé si conviene por el momento.\n",
    "y = df_sin_ceros['satisfaction']\n",
    "\n",
    "#-- Codificar solo las variables categóricas--\n",
    "\n",
    "# Variables categóricas\n",
    "encoder_cat = ce.OneHotEncoder(use_cat_names=True)\n",
    "x_encoded = encoder_cat.fit_transform(df_sin_ceros.drop(columns=['satisfaction']))\n",
    "print(x_encoded)\n",
    "\n",
    "\n",
    "# Variables categóricas ordinales\n",
    "# Crear OrdinalEncoder\n",
    "encoder_ord = OrdinalEncoder()\n",
    "# Aplicar OrdinalEncoder a múltiples variables categóricas ordinales.\n",
    "# Machaco la variable x_encoded que la recojo de la codificación anterior.\n",
    "x_encoded  = pd.DataFrame(encoder_ord.fit_transform(x_encoded), columns=x_encoded.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Concatenar la columna 'satisfaccion' de nuevo al DataFrame codificado\n",
    "df_encoded = pd.concat([x_encoded, y], axis=1)\n",
    "\n",
    "\"\"\" # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Guardar datos en ficheros\n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "x_train.to_csv(path + '/x_train.csv')\n",
    "x_test.to_csv(path + '/x_test.csv')\n",
    "y_train.to_csv(path + '/y_train.csv')\n",
    "y_test.to_csv(path + '/y_test.csv')\n",
    " \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cuando tienes un DataFrame con columnas categóricas y categóricas ordinales, es importante elegir el método de codificación adecuado que preserve la naturaleza ordinal de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor  # Esto importa pyjanitor y extiende pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a separar las variables, por un lado según sean categóricas(binarias, ordinales..) y por otro las numéricas\n",
    "\n",
    "· Categóricas\n",
    "\n",
    "· Numéricas\n",
    "\n",
    "Porque a veces un modelo va a trabajar mejor sólo con las categóricas o sólo con las numéricas.\n",
    "Además, es conveniente escalar las variables munéricas (ya sean por cambios de escala o por magnitud, o incluso 'normalizarlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro para quedarme con las numéricas, las que voy a escalar\n",
    "\n",
    "# Primero detecto las columnas que tienen solo valores de 0 y 1\n",
    "binary_cols = x_encoded.columns[x_encoded.nunique() == 2]\n",
    "\n",
    "# Luego detecto las columnas ordinales (2 a 5)\n",
    "ordinal_cols = x_encoded.columns[(x_encoded.nunique() > 2) & (x_encoded.nunique() <= 5)]\n",
    "\n",
    "# Ambas categóricas las junto \n",
    "categorical_cols = list(binary_cols) + list(ordinal_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué este orden es importante?\n",
    "\n",
    "Consistencia: Al separar primero X e y y luego hacer el split, garantizas que las filas correspondientes de X e y coincidan exactamente en los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Evitar filtraciones de datos: Si haces el split antes de separar X e y, podrías accidentalmente introducir fugas de datos o inconsistencias, lo que podría afectar la capacidad del modelo para generalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero separas la 'y' de las variables predictoras 'x'\n",
    "#Luego El split de tanto 'y' como 'x' con su correspondiente 'train' y 'test' se hace al final, cuando ya están las variables numéricas escaladas y realizado el coding y lebel en las categóricas\n",
    "#Finalmente voy a escalar las numéricas: Después de realizar el split, ajustas el escalador (Scaler) solo con el conjunto de entrenamiento (X_train). Esto asegura que las estadísticas de escalado (media, desviación estándar, etc.) no estén influenciadas por los datos de prueba.\n",
    "#Aplicar la transformación de escalado al conjunto de prueba:Una vez que el escalador se ha ajustado al conjunto de entrenamiento, usas ese mismo escalador para transformar el conjunto de prueba (X_test). Esto asegura que ambos conjuntos sean escalados de manera consistente\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "print(f'Las variables categóricas son:\\n' + '\\n'.join(categorical_cols) + '\\n')\n",
    "\n",
    "\n",
    "# Separa el dataframe en partes de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Filtro para quitar las columnas categóricas del dataframe y quedarme con las numéricas, porque son esas las que voy a escalar\n",
    "x_num_train = x_train.drop(columns=categorical_cols).columns #Aquí Sólo se están guardando el nombre de las columnas para rastrearlas\n",
    "pd.DataFrame(x_train[x_num_train]).to_csv(path+'/x_num_train_no_scaled.csv', index=False)\n",
    "\n",
    "x_num_test = x_test.drop(columns=categorical_cols).columns #Sólo cojo el nombre de las columnas para rastrearlas\n",
    "pd.DataFrame(x_test[x_num_test]).to_csv(path+'/x_num_test_no_scaled.csv', index=False)\n",
    "\n",
    "\n",
    "print(f'Las variables numéricas son:\\n' + '\\n'.join(x_num_train) + '\\n')\n",
    "\n",
    "# Crea un objeto StandardScaler y ajusta los parámetros de escalado con la parte de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "x_train_num_scaled = scaler.fit_transform(x_train[x_num_train])\n",
    "\n",
    "# Aplica los parámetros de escalado aprendidos a la parte de prueba\n",
    "x_test_num_scaled = scaler.transform(x_test[x_num_test]) #devuelve un array de arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón es que, en general, deseas mantener la separación entre los datos de entrenamiento y los datos de prueba, incluso después de la escalado. De esta manera, puedes asegurarte de que el modelo de machine learning se entrena y se evalúa correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reemplazo en 'train' las columnas numéricas sin escalar con las columnas numéricas escaladas. Por lo que ya me queda todo 'x' junto y escalado\n",
    "x_train[x_num_train] = x_train_num_scaled \n",
    "print(x_train)\n",
    "\n",
    "x_train.to_csv(path +   '/x_train_scaled.csv')\n",
    "\n",
    "# Reemplazo en 'test' las columnas numéricas sin escalar con las columnas numéricas escaladas\n",
    "x_test[x_num_test] = x_test_num_scaled\n",
    "x_test.to_csv(path + '/x_test_scaled.csv')\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos en ficheros\n",
    "\"\"\" \n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "pd.DataFrame(x_train_scaled).to_csv('x_train_scaled.csv', index=False)\n",
    "pd.DataFrame(x_test_scaled).to_csv('x_test_scaled.csv', index=False)\n",
    "y_train.to_csv(path + '/y_train.csv')\n",
    "y_test.to_csv(path + '/y_test.csv')\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histograma de la variable escalada\n",
    "plt.hist(x_test['Age'], bins=50)\n",
    "plt.title('Distribución de la variable escalada')\n",
    "plt.show()\n",
    "\n",
    "# Histograma de la variable no escalada ---> usar de A´ngel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estadísticas descriptivas de la variable escalada:')\n",
    "print(x_test['Age'].describe())\n",
    "\n",
    "print('Estadísticas descriptivas de la variable escalada:')\n",
    "#print(x_test_scaled[:, 0]).describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crea un objeto RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrena el modelo con el conjunto de entrenamiento\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evalúa el modelo con el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# ...\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calcula la accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calcula la precisión (average='weighted' for multi-class problems)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calcula el recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted',labels=['neutral or dissatisfied', 'satisfied'])\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "\"\"\" # Calcula el F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Calcula el ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "# Calcula la matriz de confusión\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicolinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train,y_train_le)\n",
    "\n",
    "\n",
    "#print(x_train.head())\n",
    "print(y_train.head())\n",
    "print(lin_reg.predict(x_train.head()))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "El problema es que el modelo de regresión lineal (LinearRegression) no entiende que tu variable objetivo es binaria.\n",
    "\n",
    "La regresión lineal es un algoritmo de aprendizaje automático que se utiliza para predecir valores continuos, no binarios. \n",
    "Cuando entrenas el modelo con tus datos, el algoritmo intenta encontrar la mejor línea que se ajuste a tus datos, pero no \n",
    "tiene en cuenta que la variable objetivo es binaria.\n",
    "\n",
    "Por lo tanto, cuando haces print(lin_reg.predict(x_train.head())), el modelo devuelve valores decimales porque está tratando de predecir un valor continuo, no un valor binario.\n",
    "\n",
    "Para solucionar este problema, debes utilizar un algoritmo de aprendizaje automático que sea adecuado para problemas de clasificación binaria, como LogisticRegression de scikit-learn. Este algoritmo entiende que la variable objetivo es binaria y devuelve probabilidades de pertenencia a cada clase, que puedes convertir en valores binarios (0 o 1) utilizando una función de umbral (threshold).\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Codificaicón de la variable objetivo\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train_le)\n",
    "\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_test_le = le.transform(y_test)  # Codifica y_test para compararlo correctamente\n",
    "y_pred = log_reg.predict(x_test)  # Predicción sobre el conjunto de prueba\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test_le, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Ejemplo de predicciones sobre nuevas muestras (primeras 5 filas del conjunto de prueba)\n",
    "print(x_test.head())\n",
    "y_pred_example = log_reg.predict(x_test.head())\n",
    "print(y_pred_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de calcular la correlación entre las variables dummy, es más útil utilizar otras técnicas para seleccionar las variables más relevantes para el modelo. Algunas opciones son:\n",
    "\n",
    "Análisis de la importancia de las características: utiliza algoritmos como Random Forest o Gradient Boosting para evaluar la importancia de cada variable en la predicción de Y.\n",
    "Selección de características: utiliza técnicas como la selección recursiva de características (RFE) o la selección de características mediante la matriz de correlación de mutual information.\n",
    "Análisis de la varianza: utiliza técnicas como la descomposición de la varianza para evaluar la contribución de cada variable a la varianza de Y.\n",
    "Recuerda que la selección de variables es un paso importante en el proceso de modelado, y es importante utilizar técnicas adecuadas para identificar las variables más relevantes para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8970287690614683\n",
      "\n",
      "Predicciones con etiquetas originales:\n",
      "\n",
      "¿Las predicciones son 'satisfied'?\n",
      "[False  True False ...  True False False]\n",
      "\n",
      "Valores reales vs. Predicciones para las primeras 5 filas:\n",
      "Real: neutral or dissatisfied - Predicción: neutral or dissatisfied\n",
      "Real: satisfied - Predicción: neutral or dissatisfied\n",
      "Real: neutral or dissatisfied - Predicción: neutral or dissatisfied\n",
      "Real: neutral or dissatisfied - Predicción: neutral or dissatisfied\n",
      "Real: neutral or dissatisfied - Predicción: satisfied\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Codificación de la variable objetivo\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)  # Codifica y_test para compararlo correctamente\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train_le)\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred = log_reg.predict(x_test)  # Predicción sobre el conjunto de prueba\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test_le, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convertir las predicciones numéricas a etiquetas originales es por pura estética del 'satiesfied'\n",
    "y_pred_example_labels = le.inverse_transform(y_pred_example)\n",
    "print(\"\\nPredicciones con etiquetas originales:\")\n",
    "\n",
    "\n",
    "y_test_example_labels = le.inverse_transform(y_test_le)\n",
    "\n",
    "\n",
    "# Verificar si las predicciones son 'satisfied'\n",
    "print(\"\\n¿Las predicciones son 'satisfied'?\")\n",
    "print(y_pred_example_labels == 'satisfied')\n",
    "\n",
    "# Mostrar los primeros 5 valores reales y predichos\n",
    "print(\"\\nValores reales vs. Predicciones:\")\n",
    "for real, pred in zip(y_pred_example_labels[:5], y_test_example_labels[:5]):\n",
    "    print(f\"Real: {real} - Predicción: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Preparación de los Algoritmos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Seleccionar un modelo y entrénalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Ajustar el modelo (optimización con hypermaprámetros, ensamblado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Presentar la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Desplegar y monitorizar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
