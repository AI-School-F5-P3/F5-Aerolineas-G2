{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "\n",
    "\n",
    "df = pd.read_csv(path + '/airline_passenger_satisfaction.csv')\n",
    "\n",
    "#Se elimina la primera columna que era el subíndice del csv\n",
    "df = df.iloc[:, 1:] \n",
    "df=df.drop(columns='id') #no sé si al final quito el id porque me estorba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay que crear una parte que sea 'test'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=22 )\n",
    "\n",
    "# test_size=0.2, este parámetro indica que deseas que el 20% de los datos se utilicen como conjunto de prueba y el 80% como conjunto de entrenamiento. \n",
    "# random_state=22 Este parámetro establece una semilla para el generador de números aleatorios que se usa para realizar la división. Esto asegura que cada vez que ejecutes el código, obtendrás la misma división de los datos en conjuntos de entrenamiento y prueba. Usar un valor de random_state fijo es una buena práctica cuando quieres que tus resultados sean reproducibles.\n",
    "\n",
    "train.to_csv(path+'df_train.csv', index=False)\n",
    "test.to_csv(path+'df_test.csv', index=False)\n",
    "#Este test no lo tocamos hasta el final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Exploración y visualización de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n\\nEl DF tiene {df.shape[0]:,} filas')\n",
    "print(f'El DF tiene {df.shape[1]} columnas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a tratar los missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar cuántos valores missing existen en el DataFrame por variable\n",
    "\n",
    "nulos={'conteo_nulos':df.isnull().sum(),'proporcion%':round(df.isnull().sum()/df.shape[0]*100, 3)}\n",
    "\n",
    "df_nulos=pd.DataFrame(data=nulos)\n",
    "print(df_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de convertir las variables hay que tratar los 'missings'.\n",
    "\n",
    "Que según hemos concluido, tantos los valores '0' como los 'espacios en blanco' son 'missing' y los vamos a eliminar. ---->Al final hemos decidido que los '0' sí se van a tener en cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero elimino los 'missings'\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "print(f'\\n\\nEl DF tiene {df.shape[0]:,} filas')\n",
    "\n",
    "\n",
    "# Compruebo que se ha eliminado\n",
    "missing={'conteo_nulos':df.isnull().sum(),'proporcion%':round(df.isnull().sum()/df.shape[0]*100, 3)}\n",
    "df_coun_missing=pd.DataFrame(data=nulos)\n",
    "print(df_coun_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo la Variable Objetivo, 'Y', de las Variables predictoras 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En este dataframe guarda la variable Objetivo, 'Y'\n",
    "y = df['satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En esta dataframe 'x' se guardan las variables predictoras\n",
    "x=df.drop(columns=['satisfaction'])\n",
    "\n",
    "print(f'Las variables son {len(x.columns)}:\\n\\n' + '\\n'.join(x.columns) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifico 'Y' en binario, aunque a veces hay modelos que trabajan igualmente bien sin codificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de la variable objetivo\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_le = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de los valores por cada columna ----> Hacer bucle para ver si hay columnas que estén desbalanceadas.\n",
    "# Para ver qué variables hay que escalar\n",
    "\n",
    "df['Customer Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora elimino los '0' pero de las columnas categóricas ordinales\n",
    "# -->Ya no, hemos decidido dejarlos !!!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a separar las variables, por un lado según sean categóricas(binarias, ordinales..) y por otro las numéricas\n",
    "\n",
    "· Categóricas\n",
    "\n",
    "· Numéricas\n",
    "\n",
    "Porque a veces un modelo va a trabajar mejor sólo con las categóricas o sólo con las numéricas.\n",
    "Además, es conveniente escalar las variables munéricas (ya sean por cambios de escala o por magnitud, o incluso 'normalizarlas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecto las variables categóricas para separarlas de las numéricas, porque es conveniente para codificar tanto las categóricas ordinales(que en este caso no es necesario porque ya están del 0 al 5) y las categóricas binarias, por un lado, y escalar las numéricas.\n",
    "\n",
    "Filtro en el dataframe 'X' las variables categóricas y las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "# Para detectar me da igual usar 'X' o usar 'X_TRAIN' porque sólo quiero el nombre de las columans\n",
    "# Función para detectar variables categóricas ordinales\n",
    "def detectar_variables_ordinales(x):\n",
    "    ordinal_columns = []\n",
    "\n",
    "    for column in x.columns:\n",
    "        # verificar si la columna es numérica\n",
    "        if pd.api.types.is_numeric_dtype(x[column]):\n",
    "            # obtener valores únicos\n",
    "            unique_values = x[column].unique()\n",
    "            # verificar si todos los valores están en el rango [1,5]\n",
    "            if set(unique_values).issubset({0, 1, 2, 3, 4, 5}):\n",
    "                ordinal_columns.append(column)\n",
    "\n",
    "    \n",
    "    return ordinal_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "variables_ordinales = detectar_variables_ordinales(x)\n",
    "\n",
    "print(f'Variables categóricas ordinales: {len(variables_ordinales)}\\n\\n' + '\\n'.join(variables_ordinales) + '\\n')\n",
    "\n",
    "\n",
    "# Resultado:\n",
    "# Variables categóricas ordinales: ['Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
    "# Ya no !!!!!  ----> De esas variables hay que quitar los '0' porque hemos decidido que son missing. Antes de hacer el one-hot-encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables que son categóricas binarias y categóricas no ordinales\n",
    "import pandas as pd\n",
    "\n",
    "def detectar_variables_categoricas(x):\n",
    "    categorias_columns = []\n",
    "\n",
    "    for column in x.columns:\n",
    "        # Verificar si la columna no es numérica\n",
    "        if not pd.api.types.is_numeric_dtype(x[column]):\n",
    "            # Obtener el número de categorías únicas\n",
    "            unique_values = x[column].nunique()\n",
    "            # Se puede agregar un límite arbitrario si se desea,\n",
    "            # por ejemplo, menos de 10 categorías únicas\n",
    "            if unique_values < 10:\n",
    "                categorias_columns.append(column)\n",
    "\n",
    "    return categorias_columns\n",
    "\n",
    "# Supongamos que tienes un DataFrame df\n",
    "variables_categoricas = detectar_variables_categoricas(x)\n",
    "\n",
    "print(f'Variables categóricas binarias y categóricas no ordinales: {len(variables_categoricas)}\\n\\n' + '\\n'.join(variables_categoricas) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junto el nombre de las variables categóricas (ya sean binarias, no ordinales y ordinales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro para quedarme con las numéricas, las que voy a escalar\n",
    "\n",
    "# Primero detecto las columnas que tienen solo valores de 0 y 1\n",
    "\"\"\" binary_cols = x_encoded.columns[x_encoded.nunique() == 2]\n",
    "\n",
    "# Luego detecto las columnas ordinales (2 a 5)\n",
    "ordinal_cols = x_encoded.columns[(x_encoded.nunique() > 1) & (x_encoded.nunique() <= 5)] \"\"\"\n",
    "\n",
    "# Ambas categóricas las junto \n",
    "categorical_cols = list(variables_categoricas) + list(variables_ordinales)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Variables categóricas en total: {len(categorical_cols)}\\n\\n' + '\\n'.join(categorical_cols) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora encuentro las variables numéricas y las filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat=x[categorical_cols]\n",
    "data_num=x.drop(columns=categorical_cols)\n",
    "\n",
    "print(f'Variables numéricas: {len(data_num.columns)}\\n\\n' + '\\n'.join(data_num.columns) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hay que sacar el 'train' y 'test' tanto de 'Y' como de 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa el dataframe en partes de entrenamiento y prueba, tanto en 'X' como en 'Y'\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_le, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**One-Hot Encoding es generalmente preferido cuando no hay un orden inherente en las categorías. De esta manera, me aseguro de que el modelo no asuma relaciones incorrectas entre las categorías.\n",
    "\n",
    "**Label Encoding podría usarse si hay un orden claro entre las categorías.\n",
    "Cuando tienes un DataFrame con columnas categóricas y categóricas ordinales, es importante elegir el método de codificación adecuado que preserve la naturaleza ordinal de la columna.\n",
    "\n",
    "Primero se debe usar OrdinalEncoder a las variables originales y luego OneHotENcoder (en nuestro caso por cómo está codificado las variable ordinales no hace falta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 2. Crear el preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), data_num.columns),\n",
    "        ('cat', OneHotEncoder(), variables_categoricas) #Usamos drop='first' en OneHotEncoder para evitar la trampa de las variables dummy.\n",
    "    ],\n",
    "    remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender_Female' 'Gender_Male' 'Customer Type_Loyal Customer'\n",
      " 'Customer Type_disloyal Customer' 'Type of Travel_Business travel'\n",
      " 'Type of Travel_Personal Travel' 'Class_Business' 'Class_Eco'\n",
      " 'Class_Eco Plus']\n",
      "9\n",
      "['Age', 'Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Gender_Female', 'Gender_Male', 'Customer Type_Loyal Customer', 'Customer Type_disloyal Customer', 'Type of Travel_Business travel', 'Type of Travel_Personal Travel', 'Class_Business', 'Class_Eco', 'Class_Eco Plus', 'Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# 3. Ajustar y transformar los datos de entrenamiento\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "\n",
    "# 4. Transformar los datos de prueba\n",
    "x_test_processed = preprocessor.transform(x_test)\n",
    "\n",
    "# 5. Convertir a DataFrames de pandas\n",
    "# Obtenemos los nombres de las columnas después del preprocesamiento\n",
    "onehot_encoder = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = onehot_encoder.get_feature_names_out(variables_categoricas) #Este método ahora genera nombres de características de salida después de aplicar el One-Hot Encoding. Asegúrate de que categorical_cols contenga las columnas que se codificarán.\n",
    "feature_names = list(data_num.columns) + list(cat_feature_names)+list(variables_ordinales)\n",
    "#print(feature_names)\n",
    "\n",
    "print(cat_feature_names)\n",
    "print(len(cat_feature_names))\n",
    "\n",
    "\n",
    "print(feature_names)\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Customer Type_Loyal Customer</th>\n",
       "      <th>Customer Type_disloyal Customer</th>\n",
       "      <th>Type of Travel_Business travel</th>\n",
       "      <th>Type of Travel_Personal Travel</th>\n",
       "      <th>...</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18595</th>\n",
       "      <td>1.761639</td>\n",
       "      <td>-0.865809</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.392586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19336</th>\n",
       "      <td>-1.083807</td>\n",
       "      <td>-0.047478</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.392586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72501</th>\n",
       "      <td>-0.554422</td>\n",
       "      <td>-0.882858</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.392586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85210</th>\n",
       "      <td>0.702868</td>\n",
       "      <td>-0.396472</td>\n",
       "      <td>2.104466</td>\n",
       "      <td>1.663422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87824</th>\n",
       "      <td>-0.355902</td>\n",
       "      <td>-1.049332</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.392586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73004</th>\n",
       "      <td>-1.414673</td>\n",
       "      <td>1.289330</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.392586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17946</th>\n",
       "      <td>0.636695</td>\n",
       "      <td>1.381593</td>\n",
       "      <td>0.805582</td>\n",
       "      <td>0.648431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100824</th>\n",
       "      <td>-1.745539</td>\n",
       "      <td>-0.103638</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.340535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52391</th>\n",
       "      <td>1.298427</td>\n",
       "      <td>1.370561</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.392586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50820</th>\n",
       "      <td>0.570522</td>\n",
       "      <td>1.319416</td>\n",
       "      <td>-0.387271</td>\n",
       "      <td>-0.392586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31079 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age  Flight Distance  Departure Delay in Minutes  \\\n",
       "18595   1.761639        -0.865809                   -0.387271   \n",
       "19336  -1.083807        -0.047478                   -0.387271   \n",
       "72501  -0.554422        -0.882858                   -0.387271   \n",
       "85210   0.702868        -0.396472                    2.104466   \n",
       "87824  -0.355902        -1.049332                   -0.387271   \n",
       "...          ...              ...                         ...   \n",
       "73004  -1.414673         1.289330                   -0.387271   \n",
       "17946   0.636695         1.381593                    0.805582   \n",
       "100824 -1.745539        -0.103638                   -0.387271   \n",
       "52391   1.298427         1.370561                   -0.387271   \n",
       "50820   0.570522         1.319416                   -0.387271   \n",
       "\n",
       "        Arrival Delay in Minutes  Gender_Female  Gender_Male  \\\n",
       "18595                  -0.392586            1.0          0.0   \n",
       "19336                  -0.392586            1.0          0.0   \n",
       "72501                  -0.392586            1.0          0.0   \n",
       "85210                   1.663422            1.0          0.0   \n",
       "87824                  -0.392586            0.0          1.0   \n",
       "...                          ...            ...          ...   \n",
       "73004                  -0.392586            0.0          1.0   \n",
       "17946                   0.648431            1.0          0.0   \n",
       "100824                 -0.340535            1.0          0.0   \n",
       "52391                  -0.392586            1.0          0.0   \n",
       "50820                  -0.392586            1.0          0.0   \n",
       "\n",
       "        Customer Type_Loyal Customer  Customer Type_disloyal Customer  \\\n",
       "18595                            1.0                              0.0   \n",
       "19336                            1.0                              0.0   \n",
       "72501                            1.0                              0.0   \n",
       "85210                            1.0                              0.0   \n",
       "87824                            1.0                              0.0   \n",
       "...                              ...                              ...   \n",
       "73004                            1.0                              0.0   \n",
       "17946                            1.0                              0.0   \n",
       "100824                           0.0                              1.0   \n",
       "52391                            1.0                              0.0   \n",
       "50820                            1.0                              0.0   \n",
       "\n",
       "        Type of Travel_Business travel  Type of Travel_Personal Travel  ...  \\\n",
       "18595                              1.0                             0.0  ...   \n",
       "19336                              0.0                             1.0  ...   \n",
       "72501                              0.0                             1.0  ...   \n",
       "85210                              1.0                             0.0  ...   \n",
       "87824                              1.0                             0.0  ...   \n",
       "...                                ...                             ...  ...   \n",
       "73004                              0.0                             1.0  ...   \n",
       "17946                              1.0                             0.0  ...   \n",
       "100824                             1.0                             0.0  ...   \n",
       "52391                              1.0                             0.0  ...   \n",
       "50820                              1.0                             0.0  ...   \n",
       "\n",
       "        Food and drink  Online boarding  Seat comfort  Inflight entertainment  \\\n",
       "18595              2.0              4.0           1.0                     5.0   \n",
       "19336              1.0              2.0           1.0                     1.0   \n",
       "72501              5.0              1.0           5.0                     5.0   \n",
       "85210              4.0              3.0           3.0                     3.0   \n",
       "87824              4.0              4.0           4.0                     4.0   \n",
       "...                ...              ...           ...                     ...   \n",
       "73004              2.0              1.0           1.0                     5.0   \n",
       "17946              1.0              2.0           3.0                     2.0   \n",
       "100824             3.0              2.0           3.0                     3.0   \n",
       "52391              3.0              3.0           5.0                     5.0   \n",
       "50820              5.0              4.0           4.0                     3.0   \n",
       "\n",
       "        On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "18595                5.0               5.0               5.0              2.0   \n",
       "19336                4.0               3.0               4.0              4.0   \n",
       "72501                4.0               3.0               5.0              5.0   \n",
       "85210                3.0               3.0               3.0              2.0   \n",
       "87824                3.0               2.0               4.0              2.0   \n",
       "...                  ...               ...               ...              ...   \n",
       "73004                2.0               5.0               5.0              1.0   \n",
       "17946                2.0               2.0               2.0              3.0   \n",
       "100824               1.0               1.0               5.0              2.0   \n",
       "52391                5.0               5.0               5.0              5.0   \n",
       "50820                3.0               3.0               3.0              3.0   \n",
       "\n",
       "        Inflight service  Cleanliness  \n",
       "18595                5.0          3.0  \n",
       "19336                5.0          1.0  \n",
       "72501                4.0          5.0  \n",
       "85210                3.0          2.0  \n",
       "87824                4.0          4.0  \n",
       "...                  ...          ...  \n",
       "73004                4.0          1.0  \n",
       "17946                2.0          1.0  \n",
       "100824               3.0          3.0  \n",
       "52391                5.0          4.0  \n",
       "50820                3.0          1.0  \n",
       "\n",
       "[31079 rows x 27 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_processed_df = pd.DataFrame(x_train_processed, columns=feature_names,index=x_train.index)\n",
    "x_test_processed_df = pd.DataFrame(x_test_processed, columns=feature_names, index=x_test.index)\n",
    "\n",
    "x_test_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "# Variables categóricas ordinales -----> no haría falta\n",
    "# Crear OrdinalEncoder\n",
    "encoder_ord = OrdinalEncoder()\n",
    "# Aplicar OrdinalEncoder a múltiples variables categóricas ordinales.\n",
    "# Machaco la variable x_train_cat que la recojo de la codificación anterior.\n",
    "x_train_ord_encod= pd.DataFrame(encoder_ord.fit_transform(x_train_cat_encod), columns=x_train_cat_encod.columns)\n",
    "\n",
    "#Hay que aplicar la transformación a la parte 'test'\n",
    "x_test_ord_encod=pd.DataFrame(encoder_ord.transform(x_test_cat_encod), columns=x_test_cat_encod.columns)\n",
    "\n",
    "# Concatenar la columna 'satisfaccion' de nuevo al DataFrame codificado\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué este orden es importante?\n",
    "\n",
    "Consistencia: Al separar primero X e y y luego hacer el split, garantizas que las filas correspondientes de X e y coincidan exactamente en los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Evitar filtraciones de datos: Si haces el split antes de separar X e y, podrías accidentalmente introducir fugas de datos o inconsistencias, lo que podría afectar la capacidad del modelo para generalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primero separas la 'y' de las variables predictoras 'x'.\n",
    "* Luego El split de tanto 'y' como 'x' con su correspondiente 'train' y 'test'\n",
    "* Finalmente voy a escalar las numéricas: Después de realizar el split, ajustas el escalador (Scaler) solo con el conjunto de entrenamiento (X_train). Esto asegura que las estadísticas de escalado (media, desviación estándar, etc.) no estén influenciadas por los datos de prueba.\n",
    "* Aplicar la transformación de escalado al conjunto de prueba:Una vez que el escalador se ha ajustado al conjunto de entrenamiento, usas ese mismo escalador para transformar el conjunto de prueba (X_test). Esto asegura que ambos conjuntos sean escalados de manera consistente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero separas la 'y' de las variables predictoras 'x'\n",
    "#Luego El split de tanto 'y' como 'x' con su correspondiente 'train' y 'test'\n",
    "#Finalmente voy a escalar las numéricas: Después de realizar el split, ajustas el escalador (Scaler) solo con el conjunto de entrenamiento (X_train). Esto asegura que las estadísticas de escalado (media, desviación estándar, etc.) no estén influenciadas por los datos de prueba.\n",
    "#Aplicar la transformación de escalado al conjunto de prueba:Una vez que el escalador se ha ajustado al conjunto de entrenamiento, usas ese mismo escalador para transformar el conjunto de prueba (X_test). Esto asegura que ambos conjuntos sean escalados de manera consistente\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón es que, en general, deseas mantener la separación entre los datos de entrenamiento y los datos de prueba, incluso después de la escalado. De esta manera, puedes asegurarte de que el modelo de machine learning se entrena y se evalúa correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# En 'train' cojo las columnas numéricas sin escalar y las reemplazo con las columnas numéricas escaladas. \n",
    "# Por lo que ya me queda todo 'x_train' junto y escalado\n",
    "#x_train[data_num.columns] = x_train_num_scaled\n",
    "\n",
    "\n",
    "x_train.to_csv(path +   '/x_train_scaled.csv')\n",
    "\n",
    "# En 'test' cojo las columnas numéricas sin escalar y las reemplazo con las columnas numéricas escaladas.\n",
    "# Por lo que ya me queda todo 'x_test' junto y escalado\n",
    "\n",
    "x_test.to_csv(path + '/x_test_scaled.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos en ficheros\n",
    "\"\"\" \n",
    "path='C:/4_F5/011_proyecto_ml/'\n",
    "pd.DataFrame(x_train_scaled).to_csv('x_train_scaled.csv', index=False)\n",
    "pd.DataFrame(x_test_scaled).to_csv('x_test_scaled.csv', index=False)\n",
    "y_train.to_csv(path + '/y_train.csv')\n",
    "y_test.to_csv(path + '/y_test.csv')\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histograma de la variable escalada\n",
    "plt.hist(x_train_processed_df['Age'], bins=50)\n",
    "plt.title('Distribución de la variable escalada')\n",
    "plt.show()\n",
    "\n",
    "# Histograma de la variable no escalada ---> usar de A´ngel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas descriptivas de la variable escalada:\n",
      "count    7.251500e+04\n",
      "mean     7.446907e-18\n",
      "std      1.000007e+00\n",
      "min     -2.142578e+00\n",
      "25%     -8.191147e-01\n",
      "50%      4.113660e-02\n",
      "75%      7.690415e-01\n",
      "max      3.018930e+00\n",
      "Name: Age, dtype: float64\n",
      "Estadísticas descriptivas de la variable escalada:\n"
     ]
    }
   ],
   "source": [
    "print('Estadísticas descriptivas de la variable escalada:')\n",
    "print(x_train_processed_df['Age'].describe())\n",
    "\n",
    "print('Estadísticas descriptivas de la variable escalada:')\n",
    "#print(x_test_scaled[:, 0]).describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histograma de la variable escalada\n",
    "plt.hist(x_train_processed_df['Age'], bins=50)\n",
    "plt.title('Distribución de la variable escalada')\n",
    "plt.show()\n",
    "\n",
    "# Histograma de la variable no escalada ---> usar de A´ngel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histograma de la variable escalada\n",
    "plt.hist(x_train_processed_df['Flight Distance'], bins=50)\n",
    "plt.title('Distribución de la variable escalada')\n",
    "plt.show()\n",
    "\n",
    "# Histograma de la variable no escalada ---> usar de A´ngel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7.251500e+04\n",
      "mean     1.469784e-18\n",
      "std      1.000007e+00\n",
      "min     -1.161652e+00\n",
      "25%     -7.775579e-01\n",
      "50%     -3.463295e-01\n",
      "75%      5.512274e-01\n",
      "max      3.804495e+00\n",
      "Name: Flight Distance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x_train_processed_df['Flight Distance'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9621609446893401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crea un objeto RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrena el modelo con el conjunto de entrenamiento\n",
    "model.fit(x_train_processed_df, y_train)\n",
    "\n",
    "# Evalúa el modelo con el conjunto de 'test'\n",
    "y_pred = model.predict(x_test_processed_df)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# ...\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calcula la accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calcula la precisión (average='weighted' for multi-class problems)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calcula el recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted',labels=['neutral or dissatisfied', 'satisfied'])\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "\"\"\" # Calcula el F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Calcula el ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "# Calcula la matriz de confusión\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicolinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train,y_train_le)\n",
    "\n",
    "\n",
    "#print(x_train.head())\n",
    "print(y_train.head())\n",
    "print(lin_reg.predict(x_train.head()))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "El problema es que el modelo de regresión lineal (LinearRegression) no entiende que tu variable objetivo es binaria.\n",
    "\n",
    "La regresión lineal es un algoritmo de aprendizaje automático que se utiliza para predecir valores continuos, no binarios. \n",
    "Cuando entrenas el modelo con tus datos, el algoritmo intenta encontrar la mejor línea que se ajuste a tus datos, pero no \n",
    "tiene en cuenta que la variable objetivo es binaria.\n",
    "\n",
    "Por lo tanto, cuando haces print(lin_reg.predict(x_train.head())), el modelo devuelve valores decimales porque está tratando de predecir un valor continuo, no un valor binario.\n",
    "\n",
    "Para solucionar este problema, debes utilizar un algoritmo de aprendizaje automático que sea adecuado para problemas de clasificación binaria, como LogisticRegression de scikit-learn. Este algoritmo entiende que la variable objetivo es binaria y devuelve probabilidades de pertenencia a cada clase, que puedes convertir en valores binarios (0 o 1) utilizando una función de umbral (threshold).\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8719392515846713\n",
      "[1 0 0 0 1]\n",
      "\n",
      "Valores reales vs. Predicciones:\n",
      "   Real  Predicción\n",
      "0     1           1\n",
      "1     0           0\n",
      "2     0           0\n",
      "3     0           0\n",
      "4     1           1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Codificaicón de la variable objetivo\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train) #codifica y_train\n",
    "y_test_le = le.transform(y_test)  # Codifica y_test para compararlo correctamente\n",
    "\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train_processed_df, y_train_le)\n",
    "\n",
    "\n",
    "# Predicción aprendida en el 'train' se aplica al conjunto de 'test'\n",
    "y_pred = log_reg.predict(x_test_processed_df)  # Predicción sobre el conjunto de 'test'\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test_le, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Ejemplo de predicciones sobre nuevas muestras (primeras 5 filas del conjunto de prueba)\n",
    "y_pred_example = log_reg.predict(x_test_processed_df.head())\n",
    "print(y_pred_example)\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': y_test_le[:5],  # Primeras 5 filas reales\n",
    "    'Predicción': y_pred_example # Primeras 5 predicciones\n",
    "})\n",
    "\n",
    "# Imprimir la tabla de resultados\n",
    "print(\"\\nValores reales vs. Predicciones:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de calcular la correlación entre las variables dummy, es más útil utilizar otras técnicas para seleccionar las variables más relevantes para el modelo. Algunas opciones son:\n",
    "\n",
    "Análisis de la importancia de las características: utiliza algoritmos como Random Forest o Gradient Boosting para evaluar la importancia de cada variable en la predicción de Y.\n",
    "\n",
    "Selección de características: utiliza técnicas como la selección recursiva de características (RFE) o la selección de características mediante la matriz de correlación de mutual information.\n",
    "\n",
    "Análisis de la varianza: utiliza técnicas como la descomposición de la varianza para evaluar la contribución de cada variable a la varianza de Y.\n",
    "\n",
    "Recuerda que la selección de variables es un paso importante en el proceso de modelado, y es importante utilizar técnicas adecuadas para identificar las variables más relevantes para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a usar más métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[15877  1706]\n",
      " [ 2274 11222]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#\n",
    "# Generar la matriz de confusión\n",
    "cm = confusion_matrix(y_test_le, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión saca sus resultados a partir de lo parte de 'test', en general (pero se puede hacer una matriz de confusión de la parte de 'train' para comparar con la matriz de 'test' y así encontrar señales de 'overfitting'. Esto lo haré luego)\n",
    "\n",
    "Para interpretar esta matriz, debemos entender qué representan cada una de las celdas:\n",
    "\n",
    "La diagonal principal (de arriba a la izquierda a abajo a la derecha) representa las observaciones que el modelo clasificó correctamente. En este caso, hay 15005 observaciones que el modelo clasificó como negativas (0) y realmente eran negativas, y 10665 observaciones que el modelo clasificó como positivas (1) y realmente eran positivas.\n",
    "La celda superior derecha (1455) representa las observaciones que el modelo clasificó como positivas (1) pero realmente eran negativas (0). Estas son llamadas \"falsos positivos\" (FP).\n",
    "La celda inferior izquierda (1500) representa las observaciones que el modelo clasificó como negativas (0) pero realmente eran positivas (1). Estas son llamadas \"falsos negativos\" (FN).\n",
    "A partir de esta matriz de confusión, podemos sacar varias conclusiones:\n",
    "\n",
    "Precisión: La precisión del modelo se puede calcular como la suma de las observaciones clasificadas correctamente (diagonal principal) dividida entre el total de observaciones. En este caso, la precisión es (15005 + 10665) / (15005 + 1455 + 1500 + 10665) ≈ 0.92. Esto significa que el modelo es capaz de clasificar correctamente alrededor del 92% de las observaciones.\n",
    "\n",
    "Sensibilidad: La sensibilidad se refiere a la capacidad del modelo para detectar observaciones positivas (1). Se puede calcular como la cantidad de verdaderos positivos (TP) dividida entre la suma de verdaderos positivos y falsos negativos (FN). En este caso, la sensibilidad es 10665 / (10665 + 1500) ≈ 0.877. Esto significa que el modelo es capaz de detectar alrededor del 87.7% de las observaciones positivas.\n",
    "\n",
    "Especificidad: La especificidad se refiere a la capacidad del modelo para detectar observaciones negativas (0). Se puede calcular como la cantidad de verdaderos negativos (TN) dividida entre la suma de verdaderos negativos y falsos positivos (FP). En este caso, la especificidad es 15005 / (15005 + 1455) ≈ 0.912. Esto significa que el modelo es capaz de detectar alrededor del 91.2% de las observaciones negativas.\n",
    "En resumen, la matriz de confusión indica que el modelo de regresión logística tiene una buena precisión y especificidad, pero una sensibilidad moderada. Esto sugiere que el modelo es capaz de clasificar correctamente la mayoría de las observaciones, pero puede tener dificultades para detectar algunas observaciones positivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirar qué es sobreajuste y cómo medirlo\n",
    "\n",
    "El 'overfitting' es un problema que ocurre cuando un modelo de machine learning se ajusta demasiado bien a los datos de entrenamiento, capturando tanto las relaciones como el ruido o patrones irrelevantes en los datos.\n",
    "Como resultado, aunque el modelo tenga un alto rendimiento en los datos de entrenamiento, su capacidad de generalización a nuevos datos o datos de prueba deficiente, lo que conduce a un bajo rendimiento de estos últimos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del Modelo de Regresión Logística, algunas señales para evaluar Overfitting podría ser:\n",
    "* Alta precisión en el conjunto de entrenamiento y baja precisión en el conjunto de prueba.\n",
    "* Matriz de confusión desequilibrada, donde el modelo clasifica correctamente en el conjunto de entrenamiento, pero falla significativamente en el conjunto de prueba.\n",
    "* Curva ROC/AUC, donde el AUC en los datos de prueba es significativamente más bajo que en los datos de entrenamiento.\n",
    "\n",
    "\n",
    "Por tanto, se pueden realizar las siguientes comprobaciones para evaluarlo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":\n",
    "\n",
    "* 1. Compara el rendimiento entre los datos de entrenamiento y prueba: Revisa las métricas de precisión (accuracy), precisión (precision), sensibilidad (recall), y el AUC en ambos conjuntos de datos. Si el rendimiento es mucho mejor en el conjunto de entrenamiento que en el conjunto de prueba, es una señal clara de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción en el conjunto de entrenamiento\n",
    "y_train_pred = log_reg.predict(x_train)\n",
    "train_accuracy = accuracy_score(y_train_le, y_train_pred)\n",
    "\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", train_accuracy)\n",
    "print(\"Precisión en el conjunto de prueba:\", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2. Curva de aprendizaje: \n",
    "Podemos graficar el rendimiento del modelo en el conjunto de entrenamiento y prueba en función del número de muestras. Si la precisión en el conjunto de prueba se estabiliza a un nivel bajo y en el conjunto de entrenamiento es muy alta, esto es una indicación de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Parámetros para la función learning_curve\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)  # Fracciones del conjunto de datos de entrenamiento que se usarán\n",
    "\n",
    "# Generar curva de aprendizaje\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    LogisticRegression(), \n",
    "    x_train, y_train_le, \n",
    "    train_sizes=train_sizes, \n",
    "    cv=5,  # Validación cruzada de 5 folds\n",
    "    scoring='accuracy',  # Medimos la precisión del modelo\n",
    "    n_jobs=-1  # Usar todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Cálculo de la media y desviación estándar para la precisión de entrenamiento y validación\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "# Graficar la curva de aprendizaje\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Precisión en entrenamiento', color='blue')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, color='blue', alpha=0.2)\n",
    "plt.plot(train_sizes, validation_scores_mean, label='Precisión en validación', color='green')\n",
    "plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std, validation_scores_mean + validation_scores_std, color='green', alpha=0.2)\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.title('Curva de aprendizaje para Regresión Logística')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo otro Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Preparación de los Algoritmos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Seleccionar un modelo y entrénalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Ajustar el modelo (optimización con hypermaprámetros, ensamblado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Presentar la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Desplegar y monitorizar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
